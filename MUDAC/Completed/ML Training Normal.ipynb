{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947d9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data \n",
    "df = pd.read_excel(\"ML Completed Subset.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f002f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute \n",
    "categorical_columns = [\n",
    "    'Program Type', 'Program', 'Little Gender', 'Little Participant: Race/Ethnicity', \n",
    "    'Little County', 'Little State', 'Big Gender', 'Big Race/Ethnicity', \n",
    "    'Big Occupation', 'Big Level of Education', 'Big County', 'Big State', \n",
    "    'Big Contact: Marital Status', 'Big Contact: Former Big/Little'\n",
    "]\n",
    "numerical_columns = [\n",
    "    'Little Age', 'Little Mean Household Income', 'Litte Median Household Income', \n",
    "    'Big Age', 'Big Mean Household Income', 'Big Median Household Income',\n",
    "    'Match Activation To Update Days', 'green_flag_count', 'red_flag_count', \n",
    "    'Match closure Discussed', 'Changing Match Type', 'COVID impact',\n",
    "    'Child/Family: Feels incompatible with volunteer', 'Child/Family: Moved',\n",
    "    'Child/Family: Lost contact with agency', 'Child/Family: Lost contact with volunteer/agency',\n",
    "    'Child/Family: Lost contact with volunteer', 'Child/Family: Moved out of service',\n",
    "    'Child/Family: Unrealistic expectations', 'Child/Family: Time constraints',\n",
    "    'Child/Family: Infraction of match rules/agency policies', 'Child/Family: Moved within service area',\n",
    "    'Child: Graduated', 'Child: Transportation Issues', 'Child: Changed school/site',\n",
    "    'Child: Lost interest', 'Child: Family structure changed', 'Child: Severity of challenges',\n",
    "    'Volunteer: Transportation Issues', 'Volunteer: Moved out of service area',\n",
    "    'Volunteer: Moved within service area', 'Volunteer: Lost contact with agency',\n",
    "    'Volunteer: Lost contact with child/agency', 'Volunteer: Feels incompatible with child/family',\n",
    "    'Volunteer: Time constraint', 'Volunteer: Deceased', 'Volunteer: Lost contact with child/family',\n",
    "    'Volunteer: Infraction of match rules/agency policies', 'Volunteer: Unrealistic expectations',\n",
    "    'Volunteer: Pregnancy', 'Volunteer: Changed workplace/school partnership',\n",
    "    'Agency: Challenges with program/partnership', 'Agency: Concern with Volunteer re: child safety',\n",
    "    'Event severity total'\n",
    "]\n",
    "\n",
    "# Categorical: most frequent\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Numerical: KNN Imputer\n",
    "num_imputer = KNNImputer(n_neighbors=5)\n",
    "df[numerical_columns] = num_imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "grouped = df.groupby('Match ID 18Char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a306f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static features (take first value as theyâ€™re consistent per match)\n",
    "static_features = [\n",
    "    'Little Age', 'Little Gender', 'Little Participant: Race/Ethnicity', 'Little County',\n",
    "    'Little State', 'Little Mean Household Income', 'Litte Median Household Income',\n",
    "    'Big Age', 'Big Gender', 'Big Race/Ethnicity', 'Big Occupation', 'Big Level of Education',\n",
    "    'Big County', 'Big State', 'Big Contact: Marital Status', 'Big Mean Household Income',\n",
    "    'Big Median Household Income', 'Big Contact: Former Big/Little', 'Program Type', 'Program'\n",
    "]\n",
    "agg_df = grouped[static_features].first()\n",
    "\n",
    "# Aggregated features from time-varying data\n",
    "agg_df['number_checkups'] = grouped.size()\n",
    "agg_df['sum_green_flags'] = grouped['green_flag_count'].sum()\n",
    "agg_df['sum_red_flags'] = grouped['red_flag_count'].sum()\n",
    "agg_df['sum_event_severity'] = grouped['Event severity total'].sum()\n",
    "agg_df['avg_update_days'] = grouped['Match Activation To Update Days'].mean()\n",
    "agg_df['max_update_days'] = grouped['Match Activation To Update Days'].max()\n",
    "\n",
    "# Flag sums (example subset; include all relevant flag columns as needed)\n",
    "flag_columns = [\n",
    "    'Match closure Discussed', 'Changing Match Type', 'COVID impact',\n",
    "    'Child/Family: Feels incompatible with volunteer', 'Child: Lost interest'\n",
    "    # Add all other flag columns here for completeness\n",
    "]\n",
    "for col in flag_columns:\n",
    "    agg_df[f'sum_{col.replace(\":\", \"_\").replace(\" \", \"_\")}'] = grouped[col].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77319063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train test split\n",
    "\n",
    "# Target variable\n",
    "agg_df['Match Length'] = grouped['Match Length'].first()\n",
    "\n",
    "# Step 3: Prepare Features and Target\n",
    "X = agg_df.drop('Match Length', axis=1)\n",
    "y = agg_df['Match Length']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Define Preprocessing Pipeline\n",
    "cat_features = [col for col in X.columns if col in categorical_columns]\n",
    "num_features = [col for col in X.columns if col not in categorical_columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "        ('num', StandardScaler(), num_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749849e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search Model Definations : \n",
    "models = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'model': GradientBoostingRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__learning_rate': [0.01, 0.1],\n",
    "            'regressor__max_depth': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model': SVR(),\n",
    "        'params': {\n",
    "            'regressor__C': [0.1, 1, 10],\n",
    "            'regressor__epsilon': [0.01, 0.1],\n",
    "            'regressor__kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'model': MLPRegressor(max_iter=1000, random_state=42),\n",
    "        'params': {\n",
    "            'regressor__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'regressor__activation': ['relu', 'tanh'],\n",
    "            'regressor__alpha': [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97c874cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - Best RMSE: 2.9415, Best Params: {}\n",
      "RandomForestRegressor - Best RMSE: 2.7296, Best Params: {'regressor__max_depth': 10, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 100}\n",
      "GradientBoostingRegressor - Best RMSE: 2.7455, Best Params: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 5, 'regressor__n_estimators': 100}\n",
      "SVR - Best RMSE: 2.7966, Best Params: {'regressor__C': 10, 'regressor__epsilon': 0.1, 'regressor__kernel': 'linear'}\n",
      "MLPRegressor - Best RMSE: 3.6566, Best Params: {'regressor__activation': 'relu', 'regressor__alpha': 0.001, 'regressor__hidden_layer_sizes': (100,)}\n",
      "\n",
      "Best Model: RandomForestRegressor\n",
      "Cross-Validation RMSE: 2.7296\n",
      "Test RMSE: 2.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run Grid search Models!\n",
    "\n",
    "best_models = {}\n",
    "for name, model_info in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model_info['model'])\n",
    "    ])\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        model_info['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1  # Use all available CPU cores\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = {\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': -grid_search.best_score_  # Convert back to positive RMSE\n",
    "    }\n",
    "    print(f\"{name} - Best RMSE: {best_models[name]['best_score']:.4f}, \"\n",
    "          f\"Best Params: {best_models[name]['best_params']}\")\n",
    "\n",
    "# Step 7: Select and Evaluate the Best Model\n",
    "best_model_name = min(best_models, key=lambda k: best_models[k]['best_score'])\n",
    "best_model = best_models[best_model_name]['best_estimator']\n",
    "best_rmse = best_models[best_model_name]['best_score']\n",
    "\n",
    "# Test set evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Cross-Validation RMSE: {best_rmse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bb3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505b6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
