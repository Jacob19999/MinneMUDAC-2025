{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57079ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Match ID 18Char Match Activation Date Completion Date  \\\n",
      "16  a1v2J000002uR0JQAU            2018-04-12      2018-04-30   \n",
      "15  a1v2J000002uR0JQAU            2018-04-12      2018-05-21   \n",
      "14  a1v2J000002uR0JQAU            2018-04-12      2018-06-29   \n",
      "18  a1v2J000002uR0JQAU            2018-04-12      2018-07-30   \n",
      "10  a1v2J000002uR0JQAU            2018-04-12      2018-08-23   \n",
      "\n",
      "                          Match Support Contact Notes   Stage  \\\n",
      "16  Question: Activities:           Answer: - Ques...  Closed   \n",
      "15  Question: Activities:           Answer: MEC wa...  Closed   \n",
      "14  Question: Activities:           Answer: MEC ha...  Closed   \n",
      "18  Question: Activities:           Answer: Suppor...  Closed   \n",
      "10  Question: Activities:           Answer: Very n...  Closed   \n",
      "\n",
      "             Little ID           Big ID  Big County  State  Big Age  ...  \\\n",
      "16  0032J00003PfZ6OQAV  0032J00003PgoV1  Washington    NaN       65  ...   \n",
      "15  0032J00003PfZ6OQAV  0032J00003PgoV1  Washington    NaN       65  ...   \n",
      "14  0032J00003PfZ6OQAV  0032J00003PgoV1  Washington    NaN       65  ...   \n",
      "18  0032J00003PfZ6OQAV  0032J00003PgoV1  Washington    NaN       65  ...   \n",
      "10  0032J00003PfZ6OQAV  0032J00003PgoV1  Washington    NaN       65  ...   \n",
      "\n",
      "   Big State  Little County Little State  POP White Pop Asians Black Others  \\\n",
      "16       NaN            NaN          NaN        NaN        NaN   NaN    NaN   \n",
      "15       NaN            NaN          NaN        NaN        NaN   NaN    NaN   \n",
      "14       NaN            NaN          NaN        NaN        NaN   NaN    NaN   \n",
      "18       NaN            NaN          NaN        NaN        NaN   NaN    NaN   \n",
      "10       NaN            NaN          NaN        NaN        NaN   NaN    NaN   \n",
      "\n",
      "   Income                                        Short Notes  \\\n",
      "16    NaN  Question: Activities: Answer: - Question: Chil...   \n",
      "15    NaN  Question: Activities: Answer: MEC was able to ...   \n",
      "14    NaN  Question: Activities: Answer: MEC had a very n...   \n",
      "18    NaN  Question: Activities: Answer: Support form gat...   \n",
      "10    NaN  Question: Activities: Answer: Very nice conver...   \n",
      "\n",
      "                                    Dated Short Notes  \n",
      "16  2018-04-30 Question: Activities: Answer: - Que...  \n",
      "15  2018-05-21 Question: Activities: Answer: MEC w...  \n",
      "14  2018-06-29 Question: Activities: Answer: MEC h...  \n",
      "18  2018-07-30 Question: Activities: Answer: Suppo...  \n",
      "10  2018-08-23 Question: Activities: Answer: Very ...  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('TrainSubset.xlsx')\n",
    "\n",
    "# Convert to date\n",
    "df['Completion Date'] = pd.to_datetime(df['Completion Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "df['Match Activation Date'] = pd.to_datetime(df['Match Activation Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "df['Match Closure Meeting Date'] = pd.to_datetime(df['Match Closure Meeting Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "df['Little Birthdate'] = pd.to_datetime(df['Little Birthdate'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "df['Big Birthdate'] = pd.to_datetime(df['Big Birthdate'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "df['Big Approved Date'] = pd.to_datetime(df['Big Approved Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "\n",
    "# Sort the data\n",
    "df_sorted = df.sort_values(by=['Match ID 18Char', 'Completion Date'], ascending=[True, True])\n",
    "\n",
    "# Fill Empty Data \n",
    "df_sorted['Match Support Contact Notes'] = df_sorted['Match Support Contact Notes'].fillna('No Updates').astype(str)\n",
    "\n",
    "df_sorted.head()\n",
    "\n",
    "# Tokenizer to shorten sentences as well as remove unwanted stuff like URLs and spaces\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "def shorten_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://[^\\s]+', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove sequences of underscores longer than 3\n",
    "    text = re.sub(r'_{4,}', '', text)\n",
    "    \n",
    "    # Split into dated blocks\n",
    "    blocks = text.split('\\n\\n')\n",
    "    shortened_blocks = []\n",
    "    \n",
    "    for block in blocks:\n",
    "        # Extract the date (assuming YYYY-MM-DD format)\n",
    "        match = re.match(r'(\\d{4}-\\d{2}-\\d{2})', block)\n",
    "        if not match:\n",
    "            continue\n",
    "        date = match.group(1)\n",
    "        content = block[len(date):].strip()\n",
    "        \n",
    "        # Split content into lines\n",
    "        lines = content.split('\\n')\n",
    "        filtered_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"Answer:\" in line:\n",
    "                question, answer = line.split(\"Answer:\", 1)\n",
    "                answer = answer.strip()\n",
    "                if answer.lower() not in ['na', 'n/a', '-', '_', '__', '___', '']:\n",
    "                    filtered_lines.append(f\"{question.strip()} Answer: {answer}\")\n",
    "            else:\n",
    "                filtered_lines.append(line.strip())\n",
    "        \n",
    "        if not filtered_lines:\n",
    "            shortened_content = content.split('\\n')[0]\n",
    "        else:\n",
    "            combined_content = ' '.join(filtered_lines)\n",
    "            sentences = sent_tokenize(combined_content)\n",
    "            key_sentences = [s for s in sentences if \"See notes\" not in s][:2]\n",
    "            shortened_content = ' '.join(key_sentences) if key_sentences else combined_content.split('\\n')[0]\n",
    "        \n",
    "        shortened_blocks.append(f\"{date} {shortened_content}\")\n",
    "    \n",
    "    return '\\n\\n'.join(shortened_blocks) if shortened_blocks else text.split('\\n\\n')[0]\n",
    "\n",
    "\n",
    "# Ensure 'Completion Date' is in datetime format\n",
    "df_sorted['Completion Date'] = pd.to_datetime(df_sorted['Completion Date'], errors='coerce')\n",
    "df_sorted['Short Notes'] = df_sorted['Match Support Contact Notes'].apply(shorten_text)\n",
    "df_sorted['Dated Short Notes'] = df_sorted['Completion Date'].astype(str) + ' ' + df_sorted['Short Notes'].fillna('').astype(str)\n",
    "\n",
    "# Display the result\n",
    "print(df_sorted.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff44f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from IPython.display import display, JSON  # For nice JSON display in Jupyter\n",
    "\n",
    "os.environ[\"XAI_API_KEY\"] = \"xai-5q7CtzPajDnu5Ucaic4kCbaMXcskpnYt2In72q49rGBrM49T10gZ0kCkTsAVw0hqrnoY2kbszKNg7IlK\"\n",
    "\n",
    "context = '''\n",
    "Follow prompt instruction explicitly without exceptions. You are a machine processing text. Your only task is to identify potential events, green flags (e.g., factors likely to enhance relationship quality and duration) and red flags (e.g., risks of early termination or poor outcomes) in the mentorship program by big brothers big sisters of america.\n",
    "\n",
    "Background:\n",
    "BBB or Agency = Big brothers’ big sisters of America organization\n",
    "LB/LS = Little Brother/Sister (Mentee Or Child)\n",
    "BB/BS = Big Brother/Sister (Mentor Or Volunteer)\n",
    "MEC or MSC = Match coordinator from BBB\n",
    "PG = Parent of LB/LS\n",
    "Current Service area = Minnesota\n",
    "\n",
    "Flags :\n",
    "Green Flag indicates any events falling near to the categories below , with a positive impact on match\n",
    "Red Flag indicates any events falling near to the categories below , with a negative impact on match\n",
    "\n",
    "Green Flags to Detect:\n",
    "•Any positive Events identified in the Rationale for Match\n",
    "•Indication that Mentor completed BBB training pre-match\n",
    "•Commitment to 18-month match\n",
    "•Shared interests/preferences in match\n",
    "•Monthly in-person/phone support from agency to mentor, youth, parent\n",
    "•High mentor satisfaction, realistic expectations\n",
    "•Youth reports positive relationship, frequent meetings\n",
    "•Demographic alignment (race, gender, religion)\n",
    "•Close geographic proximity or good transportation access\n",
    "•Positive youth traits (5 Cs: competence, confidence, connection, care, character)\n",
    "•Older, experienced mentor with empathy, flexibility, multicultural competence\n",
    "•Younger mentee (elementary–early adolescence), good relational history\n",
    "\n",
    "Red Flags to Detect:\n",
    "•No pre-match training or ongoing support\n",
    "•Mismatched interests, ignored mentor preferences\n",
    "•Infrequent/superficial staff check-ins (<6 min)\n",
    "•Mentor frustration, unrealistic expectations, youth resistance\n",
    "•No closure plan for early termination\n",
    "•Match ends <6 months (34–50% risk)\n",
    "•Younger mentor (18–25), negative attitudes, low commitment\n",
    "•Older mentee seeking autonomy, severe risk factors\n",
    "•No monthly staff support (email-only contact)\n",
    "•Inadequate BBB training, excessive/scanty staff involvement\n",
    "•Parental dissatisfaction/interference\n",
    "•Match ends <13–18 months\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "output = '''\n",
    "Response Guidence:\n",
    "\n",
    "Always return a valid JSON response:\n",
    "[\n",
    "  {\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"green_flag_count\": <number>,\n",
    "    \"red_flag_count \": <number>,\n",
    "    \"events\": {\n",
    "      \"Child/Family: Unrealistic expectations\": <score>,\n",
    "      \"Volunteer: Unrealistic expectations\": <score>,\n",
    "      ......\n",
    "    }\n",
    "  },\n",
    "]\n",
    "\n",
    "Events to Detect :\n",
    "•Match closure Discussed\n",
    "•Changing Match Type\n",
    "•COVID impact\n",
    "•Child/Family: Feels incompatible with volunteer\n",
    "•Child/Family: Moved\n",
    "•Child/Family: Lost contact with agency\n",
    "•Child/Family: Lost contact with volunteer/agency\n",
    "•Child/Family: Lost contact with volunteer\n",
    "•Child/Family: Moved out of service \n",
    "•Child/Family: Unrealistic expectationsarea\n",
    "•Child/Family: Time constraints\n",
    "•Child/Family: Infraction of match rules/agency policies\n",
    "•Child/Family: Moved within service area\n",
    "•Child: Graduated\n",
    "•Child: Transportation Issues\n",
    "•Child: Changed school/site\n",
    "•Child: Lost interest\n",
    "•Child: Family structure changed\n",
    "•Child: Severity of challenges\n",
    "•Volunteer: Transportation Issues\n",
    "•Volunteer: Moved out of service area\n",
    "•Volunteer: Moved within service area\n",
    "•Volunteer: Lost contact with agency\n",
    "•Volunteer: Lost contact with child/agency\n",
    "•Volunteer: Feels incompatible with child/family\n",
    "•Volunteer: Time constraint\n",
    "•Volunteer: Deceased\n",
    "•Volunteer: Lost contact with child/family\n",
    "•Volunteer: Infraction of match rules/agency policies\n",
    "•Volunteer: Unrealistic expectations\n",
    "•Volunteer: Pregnancy\n",
    "•Volunteer: Changed workplace/school partnership\n",
    "•Agency: Challenges with program/partnership\n",
    "•Agency: Concern with Volunteer re: child safety\n",
    "\n",
    "Critical Instructions:\n",
    "-Output format: JSON with \"date\" and \"events\" containing event-specific severity scores.\n",
    "-Severity scores: Assign scores (0–5) to each event type (e.g., \"Volunteer: Time constraint_severity\"), using your best judgement where 1 is little impact, and 5 is implicates an immediate end to the match.\n",
    "-Output dates should match input exactly\n",
    "-Exclude events where Severity == 0\n",
    "-The response must not exceed 1000 tokens.\n",
    "-If the full JSON exceeds 1000 tokens, trim earlier dates and include only the most recent dates, starting from the latest date and working backward, until the output fits within 1000 tokens.\n",
    "-Do not include any explanatory text or additional content beyond the JSON unless it fits within the token limit.\n",
    "-Assume 1 token ≈ 4 characters (including spaces and punctuation) for token estimation.\n",
    "\n",
    "'''\n",
    "\n",
    "count = 0;\n",
    "\n",
    "def parse_json_message(json_string: str) -> List[Dict[str, Any]]:\n",
    "    \n",
    "    try:\n",
    "        brace_position = json_string.index('[')\n",
    "        json_string = json_string[brace_position:]\n",
    "    except:\n",
    "        raise ValueError(\"Input does not start with '[': invalid JSON array format.\")\n",
    "\n",
    "    while True:\n",
    "        if not json_string:\n",
    "            raise ValueError(\"Couldn't fix JSON\")\n",
    "        try:\n",
    "            data = json.loads(json_string + \"]\")\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            json_string = json_string[:-1]\n",
    "            continue\n",
    "        break\n",
    "    return data\n",
    "\n",
    "def process_row(row: pd.Series, error_df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "    rationale = row[\"Rationale for Match\"]\n",
    "    query = row[\"Dated Short Notes\"]\n",
    "    matchid = row[\"Match ID 18Char\"]\n",
    "    \n",
    "    try:\n",
    "        # Assume process_grok_queries returns a JSON string\n",
    "        json_response = process_grok_queries(\"Rationale For March \" + rationale + \" Dated Short Notes : \" + query)\n",
    "        parsed_response = parse_json_message(json_response)\n",
    "        \n",
    "        print(\"------------------------------\")\n",
    "        print(parsed_response)\n",
    "    \n",
    "        return parsed_response\n",
    "    except (ValueError, json.JSONDecodeError) as e:\n",
    " \n",
    "        error_row = pd.DataFrame({\n",
    "            \"Match ID 18Char\": [matchid],\n",
    "            \"Rationale for Match\": [rationale],\n",
    "            \"Dated Short Notes\": [query],\n",
    "            \"Error\": [str(e)]\n",
    "        })\n",
    "\n",
    "        globals()[\"error_df\"] = pd.concat([error_df, error_row], ignore_index=True)\n",
    "        return None\n",
    "    \n",
    "            \n",
    "def process_grok_queries(query_str):\n",
    "    global count\n",
    "    # Retrieve the API key from the environment variable\n",
    "    api_key = os.getenv(\"XAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"XAI_API_KEY environment variable is not set.\")\n",
    "    \n",
    "    print(\"Processing: \" + query_str)\n",
    "    \n",
    "    # Initialize the OpenAI client with the Grok API base URL and API key\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://api.x.ai/v1\"\n",
    "    )\n",
    "    \n",
    "    user_content = context + \" Dated Match Notes: \" +str(query_str) + output\n",
    "    \n",
    "    cached_context = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": context\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "    cached_context,\n",
    "        {\"role\": \"user\", \"content\": query_str + output}\n",
    "    ]\n",
    "    \n",
    "    # Make API call!!\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"grok-beta\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Decode the data \n",
    "    count+=1\n",
    "    answer = response.choices[0].message.content  \n",
    "    \n",
    "    print(\"Processed: \" + str(count))\n",
    "    print(\"------------------------------\")\n",
    "    print(answer)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Process the query str column !\n",
    "\n",
    "error_df = pd.DataFrame(columns=[\"Match ID 18Char\", \"Rationale for Match\", \"Dated Short Notes\", \"Error\"])  # To store errors with matchid\n",
    "\n",
    "# Process each row and handle errors\n",
    "merged_df[\"JSON Response\"] = merged_df.apply(\n",
    "    lambda row: process_row(row, error_df), axis=1\n",
    ")\n",
    "merged_df.to_excel('combined_notes.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
